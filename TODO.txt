Collect more data as neural network does not work with this little.

Add ability to add in data as a typed string in use model

calculate confidence intervals for regression coefficients

create a column of average predictions from models 

Get futher analysis of data:
    Increase the number of cross-validation folds
    Try other cross-validation strategies such as stratified k-fold or repeated k-fold cross-validation
    Examine the data more and see if there are any in built corrolations
    Complete an error analysis (unknown)
        From chat GCP:
            Calculate prediction errors: Start by calculating the prediction errors for each data point. Subtract the predicted grades from the actual grades to obtain the errors. These errors represent the discrepancies between the model's predictions and the ground truth values.

            Visualize error distribution: Plot a histogram or density plot of the prediction errors to visualize the distribution. This will provide an overview of the types and magnitudes of errors made by the model. Look for any patterns, such as skewed or asymmetric distributions, or clusters of errors around specific values.

            Analyze error statistics: Calculate summary statistics of the prediction errors, such as mean, median, standard deviation, and quartiles. These statistics provide insights into the central tendency and variability of the errors. Evaluate whether the errors are centered around zero (indicating unbiased predictions) and assess the spread of errors.

            Identify systematic errors: Examine cases where the model consistently underperforms or overperforms. Look for patterns or common characteristics among these instances. For example, the model might struggle with predicting grades for certain subjects, specific grade ranges, or certain student profiles. Understanding these systematic errors can guide further investigation and potential improvements in the model.

            Investigate individual errors: Analyze individual instances where the model's predictions significantly deviate from the actual grades. Look for cases of high absolute errors or instances where the model fails to capture important factors. Examine the corresponding features and assess whether there are missing variables or nonlinear relationships that could contribute to the errors.

            Feature impact on errors: Assess the impact of different features on the prediction errors. Determine if certain features consistently lead to larger errors or if there are specific combinations of features that result in more accurate predictions. This analysis can help identify areas where feature engineering or data preprocessing might improve the model's performance.

            Adjust the model or data: Based on the findings from the error analysis, consider making adjustments to the model or data preprocessing steps. This could involve adding new features, removing irrelevant features, transforming variables, or addressing issues like outliers or missing data. Iteratively refine the model based on the insights gained from error analysis.


Add titles and labels to graphs

See how the models work with out the U grades, as this is potentially skewing the data to the right

The triple is all performing badly, use this to see if any particular one is performing worst then others

num_variables = len(y_true)  # Assuming y_true and y_pred have the same shape

for i in range(num_variables):
    mse = mean_squared_error(y_true[:, i], y_pred[:, i])
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true[:, i], y_pred[:, i])
    r2 = r2_score(y_true[:, i], y_pred[:, i])

    print(f"Metrics for variable {i+1}:")
    print(f"MSE: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"R-squared: {r2:.4f}")
    print()

